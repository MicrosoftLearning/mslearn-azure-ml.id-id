{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Bekerja dengan Data\n",
        "\n",
        "Data adalah fondasi di mana model pembelajaran mesin dibangun. Mengelola data secara terpusat di cloud, dan membuatnya dapat diakses oleh tim ilmuwan data yang menjalankan eksperimen dan model pelatihan di beberapa stasiun kerja dan target komputasi adalah bagian penting dari solusi ilmu data profesional apa pun.\n",
        "\n",
        "Dalam buku catatan ini, Anda akan menjelajahi dua objek Azure Machine Learning untuk bekerja dengan data: *datastore*, dan *aset data*.\n",
        "\n",
        "## Sebelum Anda memulai\n",
        "\n",
        "Anda memerlukan versi terbaru paket **azureml-ai-ml** untuk menjalankan kode di notebook ini. Jalankan sel di bawah ini untuk memverifikasi bahwa sel diinstal.\n",
        "\n",
        "> **Catatan:**\n",
        "> Jika paket **azure-ai-ml** tidak diinstal, jalankan `pip install azure-ai-ml` untuk menginstalnya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789326586
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Menyambungkan ke ruang kerja Anda\n",
        "\n",
        "Dengan paket SDK yang diperlukan terinstal, sekarang Anda siap untuk terhubung ke ruang kerja Anda.\n",
        "\n",
        "Untuk menyambungkan ke ruang kerja, kita memerlukan parameter pengidentifikasi - ID langganan, nama grup sumber daya, dan nama ruang kerja. Nama grup sumber daya dan nama ruang kerja sudah diisi untuk Anda. Anda hanya memerlukan ID langganan untuk menyelesaikan perintah.\n",
        "\n",
        "Untuk menemukan parameter yang diperlukan, klik nama langganan dan ruang kerja di kanan atas Studio. Panel akan terbuka di sebelah kanan.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> Salin ID langganan dan ganti **YOUR-SUBSCRIPTION-ID** dengan nilai yang Anda salin. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Mencantumkan datastore\n",
        "\n",
        "Saat Anda membuat ruang kerja Azure Machine Learning, Akun Azure Storage juga dibuat. Akun Penyimpanan menyertakan Blob dan penyimpanan file dan secara otomatis terhubung dengan ruang kerja Anda sebagai **penyimpanan data**. Anda dapat mencantumkan semua datastore yang tersambung ke ruang kerja Anda:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789343369
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "`workspaceblobstore` Perhatikan yang terhubung ke **kontainer azureml-blobstore-...** yang Anda jelajahi sebelumnya. menyambungkan `workspacefilestore` ke **kode-...** berbagi file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Membuat datastore\n",
        "\n",
        "Setiap kali Anda ingin menyambungkan layanan penyimpanan Azure lain dengan ruang kerja Azure Machine Learning, Anda dapat membuat datastore. Perhatikan bahwa membuat datastore, membuat koneksi antara ruang kerja Anda dan penyimpanan, itu tidak membuat layanan penyimpanan itu sendiri. \n",
        "\n",
        "Untuk membuat datastore dan menyambungkan ke penyimpanan (sudah ada), Anda harus menentukan:\n",
        "\n",
        "- Kelas untuk menunjukkan dengan jenis layanan penyimpanan apa yang ingin Anda sambungkan. Contoh di bawah ini terhubung ke penyimpanan Blob (`AzureBlobDatastore`).\n",
        "- `name`: Nama tampilan datastore di ruang kerja Azure Machine Learning.\n",
        "- `description`: Deskripsi opsional untuk memberikan informasi selengkapnya tentang datastore.\n",
        "- `account_name`: Nama Akun Azure Storage.\n",
        "- `container_name`: Nama kontainer untuk menyimpan blob di Akun Azure Storage.\n",
        "- `credentials`: Berikan metode autentikasi dan kredensial untuk mengautentikasi. Contoh di bawah ini menggunakan kunci akun.\n",
        "\n",
        "**Penting**: \n",
        "- Ganti **YOUR-STORAGE-ACCOUNT-NAME** dengan nama Akun Penyimpanan yang dibuat secara otomatis untuk Anda. \n",
        "- Ganti **XXXX-XXXX** untuk `account_key` dengan kunci akun Akun Azure Storage Anda. \n",
        "\n",
        "Ingat bahwa Anda dapat mengambil kunci akun dengan menavigasi ke [portal Azure](https://portal.azure.com), buka Akun Penyimpanan Anda, dari tab **Kunci akses**, salin Nilai **kunci** untuk key1 atau key2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Cantumkan penyimpanan data lagi untuk memverifikasi bahwa datastore baru bernama `blob_training_data` telah dibuat:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790805418
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Membuat aset data\n",
        "\n",
        "Untuk menunjuk ke folder atau file tertentu di datastore, Anda dapat membuat aset data. Ada tiga jenis aset data:\n",
        "\n",
        "- `URI_FILE` menunjuk ke file tertentu.\n",
        "- `URI_FOLDER` menunjuk ke folder tertentu.\n",
        "- `MLTABLE` menunjuk ke file MLTable yang menentukan cara membaca satu atau beberapa file dalam folder.\n",
        "\n",
        "Anda akan membuat ketiga jenis aset data untuk mengalami perbedaan di antaranya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Untuk membuat aset `URI_FILE` data, Anda harus menentukan jalur yang menunjuk ke file tertentu. Jalur dapat menjadi jalur lokal atau jalur cloud.\n",
        "\n",
        "Dalam contoh di bawah ini, Anda akan membuat aset data dengan mereferensikan jalur *lokal* . Untuk memastikan data selalu tersedia saat bekerja dengan ruang kerja Azure Machine Learning, file lokal akan secara otomatis diunggah ke datastore default. Dalam hal ini, `diabetes.csv` file akan diunggah ke folder **LocalUpload** di datastore **workspaceblobstore** . \n",
        "\n",
        "Untuk membuat aset data dari file lokal, jalankan sel berikut:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Untuk membuat aset `URI_FOLDER` data, Anda harus menentukan jalur yang menunjuk ke folder tertentu. Jalur dapat menjadi jalur lokal atau jalur cloud.\n",
        "\n",
        "Dalam contoh di bawah ini, Anda akan membuat aset data dengan mereferensikan jalur *cloud* . Jalur belum ada. Folder akan dibuat ketika data diunggah ke jalur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790818340
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Untuk membuat aset `MLTable` data, Anda harus menentukan jalur yang menunjuk ke folder yang berisi file MLTable. Jalur dapat menjadi jalur lokal atau jalur cloud. \n",
        "\n",
        "Dalam contoh di bawah ini, Anda akan membuat aset data dengan mereferensikan jalur *lokal* yang berisi file MLTable dan CSV. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Untuk memverifikasi bahwa aset data baru telah dibuat, Anda dapat mencantumkan semua aset data di ruang kerja lagi:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790835295
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Membaca data di buku catatan\n",
        "\n",
        "Awalnya, Anda mungkin ingin bekerja dengan aset data di notebook, untuk menjelajahi data dan bereksperimen dengan model pembelajaran mesin. Aset data apa pun `URI_FILE` atau `URI_FOLDER` jenis dibaca karena Anda biasanya membaca data. Misalnya, untuk membaca file CSV yang diacu aset data, Anda dapat menggunakan fungsi `read_csv()`pandas . \n",
        "\n",
        "Aset `MLTable` data jenis sudah *dibaca* oleh file **MLTable** , yang menentukan skema dan cara menginterpretasikan data. Karena data sudah *dibaca*, Anda dapat dengan mudah mengonversi aset data MLTable ke dataframe pandas. \n",
        "\n",
        "Anda harus menginstal `mltable` pustaka (yang Anda lakukan di terminal). Kemudian, Anda dapat mengonversi aset data menjadi dataframe dan memvisualisasikan data.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Menggunakan data dalam pekerjaan\n",
        "\n",
        "Setelah menggunakan notebook untuk eksperimen. Anda dapat menggunakan skrip untuk melatih model pembelajaran mesin. Skrip dapat dijalankan sebagai pekerjaan, dan untuk setiap pekerjaan Anda dapat menentukan input dan output. \n",
        "\n",
        "Anda dapat menggunakan **aset data** atau **jalur datastore** sebagai input atau output pekerjaan. \n",
        "\n",
        "Sel di bawah ini membuat skrip **move-data.py** di folder **src** . Skrip membaca data input dengan `read_csv()` fungsi . Skrip kemudian menyimpan data sebagai file CSV di jalur output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Untuk mengirimkan pekerjaan yang menjalankan skrip **move-data.py** , jalankan sel di bawah ini. \n",
        "\n",
        "Pekerjaan dikonfigurasi untuk menggunakan aset `diabetes-local`data , menunjuk ke file **diabetes.csv** lokal sebagai input. Output adalah jalur yang menunjuk ke folder di datastore `blob_training_data`baru ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790852019
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './data/diabetes.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"diabetes-local\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `URI_FOLDER` data asset, you have to specify a path that points to a specific folder. The path can be a local path or cloud path.\n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *cloud* path. The path doesn't have to exist yet. The folder will be created when data is uploaded to the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666793449117
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "datastore_path = 'azureml://datastores/blob_training_data/paths/data-asset-path/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=datastore_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"Data asset pointing to data-asset-path folder in datastore\",\n",
        "    name=\"diabetes-datastore-path\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `MLTable` data asset, you have to specify a path that points to a folder which contains a MLTable file. The path can be a local path or cloud path. \n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *local* path which contains an MLTable and CSV file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790884342
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "local_path = 'data/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=local_path,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"MLTable pointing to diabetes.csv in data folder\",\n",
        "    name=\"diabetes-table\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To verify that the new data assets have been created, you can list all data assets in the workspace again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790894246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "datasets = ml_client.data.list()\n",
        "for ds_name in datasets:\n",
        "    print(ds_name.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Read data in notebook\n",
        "\n",
        "Initially, you may want to work with data assets in notebooks, to explore the data and experiment with machine learning models. Any `URI_FILE` or `URI_FOLDER` type data assets are read as you would normally read data. For example, to read a CSV file a data asset points to, you can use the pandas function `read_csv()`. \n",
        "\n",
        "A `MLTable` type data asset is already *read* by the **MLTable** file, which specifies the schema and how to interpret the data. Since the data is already *read*, you can easily convert a MLTable data asset to a pandas dataframe. \n",
        "\n",
        "You'll need to install the `mltable` library (which you did in the terminal). Then, you can convert the data asset to a dataframe and visualize the data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666792246101
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "registered_data_asset = ml_client.data.get(name='diabetes-table', version=1)\n",
        "tbl = mltable.load(f\"azureml:/{registered_data_asset.id}\")\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Use data in a job\n",
        "\n",
        "After using a notebook for experimentation. You can use scripts to train machine learning models. A script can be run as a job, and for each job you can specify inputs and outputs. \n",
        "\n",
        "You can use either **data assets** or **datastore paths** as inputs or outputs of a job. \n",
        "\n",
        "The cells below creates the **move-data.py** script in the **src** folder. The script reads the input data with the `read_csv()` function. The script then stores the data as a CSV file in the output path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/move-data.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Count the rows and print the result\n",
        "    row_count = (len(df))\n",
        "    print('Analyzing {} rows of data'.format(row_count))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To submit a job that runs the **move-data.py** script, run the cell below. \n",
        "\n",
        "The job is configured to use the data asset `diabetes-local`, pointing to the local **diabetes.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666794414231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "# configure input and output\n",
        "my_job_inputs = {\n",
        "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
        "}\n",
        "\n",
        "my_job_outputs = {\n",
        "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml://datastores/blob_training_data/paths/datastore-path\")\n",
        "}\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python move-data.py --input_data ${{inputs.local_data}} --output_datastore ${{outputs.datastore_data}}\",\n",
        "    inputs=my_job_inputs,\n",
        "    outputs=my_job_outputs,\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"move-diabetes-data\",\n",
        "    experiment_name=\"move-diabetes-data\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}